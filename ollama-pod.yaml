apiVersion: v1
kind: Pod
metadata:
  name: ollama-pod
  labels:
    app: ollama
spec:
  initContainers:
  - name: model-loader
    image: ollama/ollama:latest
    command: ["/bin/sh", "-c"]
    # This script starts the server in background, pulls the model, then exits
    args:
      - |
        ollama serve & 
        sleep 5 && 
        ollama pull phi3 && 
        echo "Model downloaded successfully!"
    volumeMounts:
    - name: llama-storage
      mountPath: /root/.ollama
  containers:
  - name: main-container
    image: ollama/ollama:latest
    volumeMounts:
    - name: llama-storage
      mountPath: /root/.ollama
    ports:
    - containerPort: 11434
  volumes:
  - name: llama-storage
    persistentVolumeClaim:
      claimName: ollama-pvc
